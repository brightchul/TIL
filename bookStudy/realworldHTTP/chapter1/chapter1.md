# Chapter1. HTTP/1.0의 신택스 : 기본이 되는 네 가지 요소

  이번 장에서의 HTTP의 4가지 요소

- 메서드와 경로
- 헤더
- 바디
- 스테이터스 코드

​      

## 1.1 HTTP의 역사

HTTP는 웹 브라우저와 웹 서버가 통신하는 절차와 형식을 규정한 것이다. 

- 1990년 : HTTP/0.9
- 1996년 : HTTP/1.0
- 1997년 : HTTP/1.1
- 2005년: HTTP/2

​                

> 프로토콜과 관련된 고유 명사

| 이름   | 정신 명칭                                          | 역할/의미                                                    |
| ------ | -------------------------------------------------- | ------------------------------------------------------------ |
| IETF   | 인터넷 기술 태스크 포스                            | 인터넷의 상호 접속성을 향상시키는 것을 목적으로 만들어진 임의 단체 |
| RFC    | Request For Comments                               | IETF가 만든 규약 문서                                        |
| IANA   | Internet Assigned Numbers Authority                | 포트 번호와 파일 타입(Contect-Type) 등 웹에 관한 데이터 베이스를 관리하는 단체 |
| W3C    | World Wide Web Consortium                          | 웹 관련 표준화를 하는 비영리 단체                            |
| WHATWG | Web Hypertext Application Technology Working Group | 웹 관련 규격을 논의하는 단체. W3C와 겸하는 멤버도 많다.      |

다양한 프로토콜이 RFC로 정의됐습니다. 인터넷이 서로 연결되는 것도, 메일이 도달하는 것도 모두 RFC로 정해진 규칙을 따라 인터넷 세계의 시스템이 만들어졌기 때문이다. RFC('Request for Comments')는 IETF라는 조직이 중심으로 해서 통신의 상호접속성 유지를 위한 공통화된 사양서 모음이다. 

​                    

### 1.1.1 테스트 에코 서버 실행

Go lang을 이용해 통신 내용을 그대로 콘솔에 표시하는 에코 서버

```go
import (
	"fmt"
	"log"
	"net/http"
	"net/http/httputil"
)

func main() {
	var httpServer http.Server
  
  // "/" 경로일 떄 handler를 호출하게 함
	http.HandleFunc("/", handler)
	log.Println("start http listening: 18888")
	httpServer.Addr = ":18888"
	log.Println(httpServer.ListenAndServe())

}

func handler(w http.ResponseWriter, r *http.Request) {
  // DumpRequest 함수를 써서 요청에 포함된 정보를 텍스트로 화면에 출력한다.
	dump, err := httputil.DumpRequest(r, true)

	if err != nil {
		http.Error(w, fmt.Sprint(err), http.StatusInternalServerError)
		return
	}
	fmt.Println(string(dump))
	fmt.Fprint(w, "<html><body>hello</body></html>\n")

}

```

​               

### 1.1.2 도커 설치

예제 중 프록시 서버를 이용할 때 도커를 사용한다.

​                

## 1.2 HTTP/0.9로 할 수 있는 것을 시험하다.

HTTP/0.9는 단순한 프로토콜로 텍스트 정보가 적힌 페이지 경로를 서버에 지정해서 해당 페이지를 가져오기만 하는 프로토콜이다. 0.9 버전은 현행 프로토콜과 하위 호환성이 없으므로 1.0을 사용한다.

```
$ curl --http1.0 http://localhost:18888/greeting
<html><body>hello</body></html>
```

```
// 서버 측 로그
2021/01/09 17:12:56 start http listening: 18888
GET /greeting HTTP/1.0
Host: localhost:18888
Connection: close
Accept: */*
User-Agent: curl/7.64.1
```

0.9 기능은 이것뿐으로, 웹사이트의 페이지를 서버에 요청하고, 그 응답으로 웹사이트의 내용을 받아온다. 수신한 후에는 서버와 연결이 끊어진다. 포트 번호를 생략했을 때는 기본으로 80번이 된다. curl커맨드는 URI를 사용하지만, 서버가 받아들이는 것은 /greeting 이라는 경로 부분뿐이다.

또한 검색과 관련해서 주소 끝에 ? 기호와 단어(+로 구분)를 붙여 검색요청을 보낸다. 검색방법은 지금과 마찬가지로 서버가 결정하고 요청하는 쪽은 검색할 단어를 입력받아 전송하는 기능만 있었다.

```
http://example.com/?search+word
```

```
$ curl --http1.0 --get --data-urlencode "search word" http://localhost:18888
```

`--data-urlencode` 는 `--get` 의 유무로 동작이 달라진다. `--get` 이 있을 떄는 `--data-urlencode` 는 URL 끝에 쿼리를 붙인다. data-urlencode는 쿼리 안의 공백이나 URL로 사용할 수 없는 문자가 있으면 치환한다. 치환 규칙은 브라우저마다 약간 다르지만 거의 같아서 동작에 미치는 영향은 없다. 사용할 수 없는 문자가 없으면 더 짧은 `--data` , `-d` 도 쓸 수 있다.

​               

#### 정리

- HTTP/0.9는 매우 단순하고 "브라우저가 문서를 요청하면 서버는 데이터를 반환한다."이다.
- 하나의 문서를 전송하는 기능밖에 없다.
- 통신하는 모든 내용을 HTML문서로 가정하여 다운로드할 컨텐츠의 형식을 서버가 전달할 수단이 없다.
- 클라이언트 쪽에서 검색 이외의 요청을 보낼수 없다.
- 새로운 문장을 전송하거나 갱신 또는 삭제할 수 없다.
- 요청이 올바른지, 서버가 올바르게 응답했는지 아는 방법이 없다.

​                

## 1.3 HTTP/0.9에서 1.0으로의 여정

필요..x

​                  

## 1.4 HTTP의 조상 (1) 전자 메일

전자 메일에 헤더가 존재하고 본문 이외의 모든 정보가 포함되어 있다. HTTP에도 이 전자메일과 같은 형식의 헤더가 도임되었다. 헤더 중 알기쉬운 부분만 보자,

​                    

### [클라이언트 -> 서버] 헤더

- User-Agent : 클라이언트가 자신의 애플리케이션 이름을 넣는 곳. curl, 브라우저, 피처폰이나 스마트폰이나 피씨의 경우 브라우저의 종류나 버전을 구분할 수 있다. 다만 역사적 경위로 여러 브라우저가 `모질라 브라우저와 같고, 사파리와 같고, 크롬과 같은 엣지` 와 같이 자신의 기능을 내포하는 다른 브라우저를 나열하는 식으로 이름을 댄다.
- Referer: 서버에서 참고하는 추가 정보. 클라이언트가 요청을 보낼 때 보고 있던 페이지의 URL을 보낸다. 페이지의 참조원을 서버가 참조하는 데 이용한다. 
- Authorization: 특별한 클라이언트에만 통신을 허가할 때 인증 정보를 서버에게 전달한다. RFC에서는 몇 가지 표준 형식 (Basic/Digest/Bearer)를 정했지만, AWS, github API 등에서는 웹 서비스 자체 표기를 요구하기도 한다.

​                  

### [서버 -> 클라이언트] 헤더

- Content-Type : 파일 종류를 지정, 여기에는 MIME 타입이라는 식별자를 기술한다. MIME 타입은 전자메일을 위해 만들어진 식별자다.
- Content-Length : 바디 크기. 만약 다음 헤더에서 소개하는 압축이 이루어지는 경우는 압축 후의 크기가 들어간다.
- Content-Encoding : 압축이 이루어진 경우 압축 형식을 설명한다.
- Date : 문자 날짜

또한 이 밖에 X-로 시작되는 헤더는 가 ㄱ애플리케이션이 자유롭게 사용해도 좋다고 디어 있다.

​                     

### 1.4.1 헤더의 전송

헤더를 보내기 위해 `--header="헤더행"` 아니면 단축형 `-H` 헤더행 옵션을 사용한다. 이번에는 테스트용 독자 헤더로서 X-를 붙여서 보낸다.

```shell
$ curl --http1.0 -H "X-Test: helloTest" http://localhost:18888
```



```
// 아무것도 추가하지 않아도 User-Agent, Accept 헤더를 전송한다.

GET / HTTP/1.0
Host: localhost:18888
Connection: close
Accept: */*
User-Agent: curl/7.64.1			
X-Test: helloTest
```

RFC에서는 같은 헤더를 여러 번 보내는 것도 허용한다.받는 쪽에서는 여러 방식으로 처리한다. (net/http패키지는 배열로 처리)

```
curl --http1.0 -H "X-Test: helloTest" -H "X-Test: NI" http://localhost:18888
```

Go 언어의 net/http 패키지는 `-`으로 구분되는 단어가 나열된 것으로 간주해, 단어의 시작은 대문자, 이후에는 소문자로 정규화 한다. 정규화 방법이나 복수의 같은 이름의 헤더를 처리하는 방법은 언어 및 프레임워크에 따라 달라진다.



자주 사용되는 헤더는 curl 커맨드에서 타이핑 수를 줄일 수 있게 별칭 alias를 준비했다. `--user-agent` (-A)를 사용하면 서버에서 보는 클라이언트의 종류가 바뀐다.

```shell
$ curl -v --http1.0 -A "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)" http://localhost:18888

$ curl -v --http1.0 -H "User-Agent: Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)" http://localhost:18888
```

​            

### 1.4.2 헤더 수신

curl -v 옵션을 지정하면, 서버에서 반환하는 헤더도 표시된다. 클라이언트가 전송하는 헤더와 서버에서 반환하는 헤더의 형식은 같지만, 필드 이름은 같은 것도 다른 것도 있다.

​                

### 1.4.3 MIME 타입

MIME 타입은 파일의 종류를 구별하는 문자열로, 전자메일을 위해 만들어졌다. 웹 브라우저는 OS와 별도로 파일 종류별로 어떤 동작을 할지 관리한다. 파일 종류에 따라 브라우저 화면에 표시하거나 '저장' 대화창을 표시하는 기능을 제공한다. 이 때 파일 종류를 나타내는 식별자가 MIME 타입이다.



웹 서버에서 HTML을 보낼 경우 서버의 응답 헤더에 다음과 같은 MIME 타입을 설정한다.

```
Content-Type: text/html; charset=utf-8
```







​               

### 1.4.4 Content-Type과 보안

브라우저 세계에서 파일 종류를 특정할 때 Content-Type헤더에 지정된 MIME 타입을 사용하는데 확장자를 쓰려고 해도 웹사이트에 따라서는 확장자가 전송되지 않을 수 있다.

IE에서는 인터넷 옵션에따라 MIME 타입이 아닌 내용을 보고 파일 형식을 추측하려고 했는데, 이런 동작을 **컨텐츠 스니핑**(content, sniffing) 이라고 한다. 하지만 스크립트가 있으면 브라우저가 파일을 실행해버릴 수 있어서 보안 취약점이 될 수 있다. 따라서 서버에서 다음과 같은 헤더를 전송해 브라우저가 추측하지 않도록 지시하는 것이 현재의 주류 방법이다.

```
X-Content-Type-Option: nosniff
```





​                    

### 1.4.5 전자메일과의 차이

#### 전자메일 포맷과 HTTP 비교

- `헤더 + 본문` 구조는 같다.
- HTTP 요청에서는 선두에 `메서드 + 패스` 행이 추가된다.
- HTTP 응답에서는 선두에 스테이터스 코드가 추가된다.

약간의 차이점이 있지만 기본은 동일하다. 그래서 HTTP 통신은 고속으로 전자 메일이 왕복하는 것이라고 할 수 있다.



​                    

## 1.5 HTTP의 조상 (2) 뉴스그룹

뉴스그룹은 분산 아키텍처로 되어 있다. 사용자는 서버에 구독하는 최신 기사를 요청하고 기사가 있으면 가져온다. 웹처럼 모든 사용자가 한 곳의 서버에 접속하러 가는 것이 아니다. 복수의 서버가 마스터/슬레이브 구조로 연결되어 있어, 슬레이브의 서버도 클라이언트처럼 마스터 서버에 접속하고, 정보를 가져와 로컬에 저장한다. 저장 용량에 제한이 있어 모든 기사가 유지되는 것은 아니며 오래된 것부터 지워간다. 

HTTP는 뉴스그룹으롭터 메서드와 스테이터스 코드 라는2가지 기능을 도입했다.

​                       

### 1.5.1 메서드

HTTP 1.0단계에서의 메서드

- GET : 서버에 헤더와 컨텐츠 요청
- HEAD : 서버에 헤더만 요청
- POST : 새로운 문서 투고
- PUT : 이미 존재하는 URL의 문서를 갱신한다.
- DELETE : 지정된 URL의 문서를 삭제한다. 삭제에 성공하면 삭제된 URL은 무효가 된다.

이외 여러 메서드들이 있다. (별로 안중요해서 제외)

```
# --request=POST 또는 -X POST를 사용한다.
$ curl --http1.0 -X POST http://localhost:18888/greeting

# -X HEAD의 단축형으로는 --head, -I 옵션이 있다.
# -d, -F 옵션이 사용되고 -X가 없다면 POST가 된다.
```

​                   

### 1.5.2 스테이터스 코드

- 100번대 : 처리가 계속됨을 나타낸다. 
- 200번대 : 성공했을 때의 응답
- 300번대 : 서버에서 클라이언트로의 명령, 오류가 아니라 정상 처리의 범주. 리다리렉트나 캐시 이용 지시
- 400번대 : 클라이언트가 보낸 요처엥 오류가 있다.
- 500번대 : 서버내부에서 오류가 발생했다.





​               

## 1.6 리디렉트

리다이렉트에는 5가지 종류가 있다.

| status code            | 메서드 변경 | 영구적/일시적 | 캐시        | 설명                              |
| ---------------------- | ----------- | ------------- | ----------- | --------------------------------- |
| 301 Moved Permanently  | ㅇ          | 영구적        | 한다        | 도메인 전송, 웹사이트 이전, HTTPS |
| 302 Found              | ㅇ          | 일시적        | 지시에 따름 | 일시적 관리, 모바일 기반 전송     |
| 303 See Other          | 허가        | 영구적        | 하지 않음   | 로그인 후 페이지 전환             |
| 307 Temporary Redirect |             | 일시적        | 지시에 따름 | RFC 7231에서 추가                 |
| 308 Moved Permanently  |             | 영구적        | 한다.       | RFC 7538에서 추가                 |



새 도메인을 얻어 서버의 컨텐츠를 이동한 경우나 HTTP로 운영되던 페이지를 HTTPS로 전환된 경우에는 예전 페이지를 볼 일이 없다. 이 때는 영구적인 리다이렉트가 된다. 점검 기간에만 요청을 관리 화면으로 리다이렉트할 경우는 점검이 끝나면 복구해 다시 활성화할 것이므로 일시적인 리다이렉트를 사용한다.

메서드 변겅은 첫 번째 요청이 POST이고, 두 번째 이후에 GET이나 HEAD를 사용할 경우에 사용자에게 확인할 필요 없이 실시할 수 있는지이다.



### 메서드 변경의 필요성 차이

- 301/308 : 요청된 페이지가 다른 장소로 이동했을 떄 사용한다. 영구적으로 이동한다. 검색 엔진도 이 응답을 받으면 기존 페이지의 평가를 새로운 페이지로 계승한다. 구글은 검색 엔진에 페이지 이동을 전하는 수단으로서 301을 사용할 것을 권장한다.
- 302/307 : 일시적인 이동이다. 모바일 전용 사이트로 이동하거나 관리 페이지를 표시한다.
- 303 : 요청된 페이지에 반환할 컨텐츠가 없거나 혹은 원래 반환할 페이지가 다로 있을 때, 그쪽으로 이동시키려고 사용한다. 예를 들면, 로그인 페이지를 사용해 로그인한 후 원래 페이지로 이동하는 경우에 사용한다.

클라이언트는 Location 헤더 값을 보고 다시 요청한다. 재전송할 때는 헤더 등도 다시 보낸다.

curl 커맨드에 -L를 부여하면 응답이 300번대이고 게다가 응답 헤더에 Location 헤더가 잇으면 그 헤더에서 지정된 URL에 다시 요청을 보낸다. 또한 스테이터스 코드가 301, 302, 303이고 GET 이외의 메서드인 경우에는 GET으로 리다이렉트를 다시 보낸다. 메서드를 바꿀수 없게 하는 옵션도 있다. `--post301, --post032, --post303  `   

기본으로 최대 50번짜리 리다이렉트한다. 리 다이렉트 횟수도 `--max-redirs` 옵션으로 지정할 수 있다.

Go lang 기본 설정에는 리다이렉트는 10회로 제한되어 있다.

리다이렉트는 단점도 있다. 리다이렉트 하는 곳이 다른 서버라면 리다이렉트 할 때마다 TCP 세션 접속, HTTP 송수신으로 두 번 왕복 통신이 발생한다. 리다이렉트 수가 늘어나면, 그만큼 표시에 걸리는 시간이 늘어난다. 





​                  

## 1.7 URL

URL(Uniform Resource Locator)은 장소로 문서 등의 리소스를 특정하는 수단을 제공한다. 즉 주소로 봐야 한다. URN은 이름 그 자체이다. RFC 3305에서 URL은 관용 표현, 공식 표기는 URI가 되었지만 URL이 일반적으로 널리 사용된다.

​               

### 1.7.1 URL의 구조

```
ex) https://www.oreilly.co.jp/index.shtml
```

스키마://호스트명/경로

- 스키마 : https
- 호스트명 : www.oreilly.co.jp
- 경로 : index.shtml

URL 사양에 포함되는 모든 요소가 들어간 예제는 다음과 같은 형식이 된다.

```
스키마://사용자:패스워드@호스트명:포트/경로#프래그먼트?쿼리
```

스키마 해석은 브라우저의 책임이다. 브라우저는 스키마를 보고 적절한 접속 방법을 선택해야 한다. 실제로 통하는 곳은 **호스트명**으로 지정된 서버이다. IP주소마다 65,535개의 포트가 있다. 같은 주소라도 포트가 다르면 독립적으로 복수의 서버를 운영해 서비스를 제공할 수 있다. 포트가 생략되면 스키마별 기본 포트를 사용한다.

프래그먼트는 HTML에서 페이지내 링크의 앵커를 지정하는 데 쓰인다.

쿼리는 검색 용어를 지정하거나 표시하고 싶은 웹페이지에 대해서 특정 파라미터를 부여하는데 사용한다.

URL을 구성하는 문자는 ASCII문자열로 영문자와 숫자, 그리고 몇 개의 기호만 표시할 수 있지만, RFC2718에서는 UTF-8로 URL을 인코딩해서 다국어 문자도 다룰 수 있게 되었다. 다만 브라우저에 따라서 다를수도 있다.

참고로 한자 한글자가 UTF8로 3바이트, URL 인코딩으로 9바이트가 된다.

HTTP/2(RFC7131)에서는 URL이 지나치게 길 때 414 URI TooLong 스테이터스 코드가 추가되었다.

​               

### 1.7.2 URL의 국제화





​                

## 1.8 바디





​                 

### 1.8.1 GET 요청 시의 바디





​                      

## 1.9 마치며





​                